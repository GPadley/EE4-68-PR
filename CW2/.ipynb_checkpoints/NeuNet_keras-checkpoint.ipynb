{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import json\n",
    "train_idx = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['train_idx'].flatten()\n",
    "camId = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['camId'].flatten()\n",
    "filelist = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['filelist'].flatten()\n",
    "gallery_idx = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['gallery_idx'].flatten()\n",
    "labels = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['labels'].flatten()\n",
    "query_idx = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['query_idx'].flatten()\n",
    "with open('PR_data/feature_data.json', 'r') as f:\n",
    "    features = np.array(json.load(f))\n",
    "train_idx -= 1\n",
    "gallery_idx -= 1\n",
    "query_idx -= 1\n",
    "features = np.divide(features,np.amax(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features[train_idx.tolist()]\n",
    "gallery_features = features[gallery_idx.tolist()]\n",
    "query_features = features[query_idx.tolist()]\n",
    "\n",
    "train_label = labels[train_idx.tolist()]\n",
    "gallery_label = labels[gallery_idx.tolist()]\n",
    "query_label = labels[query_idx.tolist()]\n",
    "\n",
    "train_cam = camId[train_idx.tolist()]\n",
    "gallery_cam = camId[gallery_idx.tolist()]\n",
    "query_cam = camId[query_idx.tolist()]\n",
    "\n",
    "labeled_train = np.asarray(list(zip(train_features, train_label, train_cam)))\n",
    "labeled_gallery = np.asarray(list(zip(gallery_features, gallery_label, gallery_cam)))\n",
    "labeled_query = np.asarray(list(zip(query_features, query_label, query_cam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalise training data into input triples and output pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "from more_itertools import locate\n",
    "\n",
    "in_triples_train = np.empty((7368, 3), int)\n",
    "out_pairs_train =  np.empty((7368, 2), int)\n",
    "for i in range(labeled_train.shape[0]) :\n",
    "\n",
    "    \n",
    "    current_id = labeled_train[i][1]\n",
    "    current_cam = labeled_train[i][2]\n",
    "    #ensure there are three unique ID's randomly selected\n",
    "    rand_id1 = rand.choice(train_label)\n",
    "    rand_id2 = rand.choice(train_label)\n",
    "    while not(rand_id1 != current_id) and not(rand_id2 != current_id) and not(rand_id1 != rand_id2) :\n",
    "        rand_id1 = rand.choice(train_label)\n",
    "        rand_id2 = rand.choice(train_label)\n",
    "\n",
    "\n",
    "    triple_set = list(locate(labeled_train, lambda x: \n",
    "                        (x[1] == current_id and x[2] != current_cam)  \n",
    "                        or (x[1] == rand_id1 and x[2] != current_cam)\n",
    "                        or (x[1] == rand_id2 and x[2] != current_cam)\n",
    "                            ))\n",
    "\n",
    "    triple_1 = rand.choice(triple_set)\n",
    "    triple_2 = rand.choice(triple_set)\n",
    "    while triple_1 == triple_2 : \n",
    "        triple_1 = rand.choice(triple_set)\n",
    "        triple_2 = rand.choice(triple_set)\n",
    "\n",
    "    in_triples_train[i] = [triple_1, i, triple_2]\n",
    "\n",
    "    out_pairs_train[i] = [(current_id == labeled_train[triple_1][1]),(current_id == labeled_train[triple_2][1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalise test data into input triple and output pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5328,) (1400,)\n"
     ]
    }
   ],
   "source": [
    "import random as rand\n",
    "from more_itertools import locate\n",
    "print(gallery_idx.shape, query_idx.shape)\n",
    "\n",
    "in_triples_test = np.empty((5328, 3), int)\n",
    "out_pairs_test =  np.empty((5328, 2), int)\n",
    "for i in range(labeled_gallery.shape[0]) :\n",
    "\n",
    "    \n",
    "    current_id = labeled_gallery[i][1]\n",
    "    current_cam = labeled_gallery[i][2]\n",
    "    #ensure there are three unique ID's randomly selected\n",
    "    rand_id1 = rand.choice(query_label)\n",
    "    rand_id2 = rand.choice(query_label)\n",
    "    while not(rand_id1 != current_id) and not(rand_id2 != current_id) and not(rand_id1 != rand_id2) :\n",
    "        rand_id1 = rand.choice(query_label)\n",
    "        rand_id2 = rand.choice(query_label)\n",
    "\n",
    "\n",
    "    triple_set = list(locate(labeled_query, lambda x: \n",
    "                        (x[1] == current_id and x[2] != current_cam)  \n",
    "                        or (x[1] == rand_id1 and x[2] != current_cam)\n",
    "                        or (x[1] == rand_id2 and x[2] != current_cam)\n",
    "                            ))\n",
    "\n",
    "    triple_1 = rand.choice(triple_set)\n",
    "    triple_2 = rand.choice(triple_set)\n",
    "    while triple_1 == triple_2 : \n",
    "        triple_1 = rand.choice(triple_set)\n",
    "        triple_2 = rand.choice(triple_set)\n",
    "\n",
    "    in_triples_test[i] = [triple_1, i, triple_2]\n",
    "\n",
    "    out_pairs_test[i] = [(current_id == labeled_query[triple_1][1]),(current_id == labeled_query[triple_2][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.empty((7368, 3, 2048), float)\n",
    "x_test = np.empty((5328, 3, 2048), float)\n",
    "for i in range(in_triples_train.shape[0]):\n",
    "    x_train[i] = train_features[in_triples_train[i]]\n",
    "for i in range(in_triples_test.shape[0]):\n",
    "    x_test[i][0] = query_features[in_triples_test[i][0]]\n",
    "    x_test[i][1] = gallery_features[in_triples_test[i][1]]\n",
    "    x_test[i][2] = query_features[in_triples_test[i][2]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = out_pairs_train\n",
    "y_test = out_pairs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (3, 2048, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7368 samples, validate on 5328 samples\n",
      "Epoch 1/10\n",
      "7368/7368 [==============================] - 17s 2ms/step - loss: 0.3170 - acc: 0.6796 - val_loss: 0.0583 - val_acc: 0.8277\n",
      "Epoch 2/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1464 - acc: 0.7135 - val_loss: 0.0686 - val_acc: 0.6866\n",
      "Epoch 3/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1406 - acc: 0.7219 - val_loss: 0.0343 - val_acc: 0.8159\n",
      "Epoch 4/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1380 - acc: 0.7224 - val_loss: 0.0279 - val_acc: 0.8348\n",
      "Epoch 5/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1365 - acc: 0.7329 - val_loss: 0.0286 - val_acc: 0.7791\n",
      "Epoch 6/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1355 - acc: 0.7261 - val_loss: 0.0299 - val_acc: 0.8707\n",
      "Epoch 7/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1348 - acc: 0.7212 - val_loss: 0.0244 - val_acc: 0.8223\n",
      "Epoch 8/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1345 - acc: 0.7332 - val_loss: 0.0242 - val_acc: 0.8369\n",
      "Epoch 9/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1341 - acc: 0.7512 - val_loss: 0.0213 - val_acc: 0.8063\n",
      "Epoch 10/10\n",
      "7368/7368 [==============================] - 12s 2ms/step - loss: 0.1335 - acc: 0.7575 - val_loss: 0.0193 - val_acc: 0.8084\n",
      "Test loss: 0.01934667142282356\n",
      "Test accuracy: 0.8083708708708709\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-9e2d04d6d771>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "x_pred = np.empty((1, 3, 2048), float)\n",
    "x_pred[0][0] = query_features[1]\n",
    "x_pred[0][1] = gallery_features[0]\n",
    "x_pred[0][2] = query_features[0]\n",
    "x_pred = x_pred.reshape(1, 3, 2048, 1)\n",
    "print(model.predict(x_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "    predict([query[i], [Test_data], [query[!i])                           \n",
    "```\n",
    "- ensure query[!i] does not use the same camera as test_data\n",
    "- for each i generate highest probability test_data matches to it with all other queries !i (set to zero for invalid !i)\n",
    "- sort the list of probabilities indexed for query[i]\n",
    "- choose top *r* depending on rank\n",
    "- gereate score 1 or 0 dependin on if the correct match is found within that rank\n",
    "- repeat for all Test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.empty((5328, 1400, 2))\n",
    "\n",
    "for i in range(labeled_gallery.shape[0]) :\n",
    "    j_pred = np.empty((1400, 2)\n",
    "    \n",
    "    for j in range(labeled_query.shape[0]) :\n",
    "        if labeled_query[j][2] == labeled_gallery[i][2] : #check for same cam\n",
    "                      continue\n",
    "        k_best_pred = 0\n",
    "        \n",
    "        for k in range(labeled_query.shape[0]) :\n",
    "            if k == j or labeled_query[k][2] == labeled_gallery[i][2]  : #check for same data point or same cam\n",
    "                      continue\n",
    "          \n",
    "            x_pred = np.empty((1, 3, 2048), float)\n",
    "            x_pred[0][0] = query_features[j]\n",
    "            x_pred[0][1] = gallery_features[i]\n",
    "            x_pred[0][2] = query_features[k]\n",
    "            x_pred = x_pred.reshape(1, 3, 2048, 1)\n",
    "            k_pred = model.predict(x_pred)[0]\n",
    "                      \n",
    "            if k_pred > k_best_pred :\n",
    "                      k_best_pred = k_pred\n",
    "        \n",
    "        j_pred[j] = [k_best_pred, labeled_query[j][1]] #store best prediction and its ID\n",
    "    \n",
    "    predictions[i] = argsort(-j_pred, axis=0) #sort list by descending probability\n",
    "\n",
    "\n",
    "#predictions should now be an sorted array of best predictions of each \n",
    "#gallery image in descenting order in a list with the corresponding predicted ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the rank accuracies of the resulting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [1,5,10] #set ranks in a list to check\n",
    "rank_scores = np.empty( (len(ranks), 5328) )\n",
    "for i in range(predicitons.shape[0]) :\n",
    "     for j in range(len(ranks)) : \n",
    "            for k in range(ranks[j])\n",
    "            \n",
    "                if prections[i][k][1] == labeled_gallery[i][1] :\n",
    "                    rank_scores[j][i] = 1\n",
    "                    \n",
    "\n",
    "for i in range(rank_scores.shape[0]) :\n",
    "    print('Rank: ', ranks[i], ' Accuracy: ', np.sum(rank_scores[i])/5328)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
