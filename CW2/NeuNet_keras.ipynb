{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import json\n",
    "train_idx = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['train_idx'].flatten()\n",
    "camId = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['camId'].flatten()\n",
    "filelist = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['filelist'].flatten()\n",
    "gallery_idx = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['gallery_idx'].flatten()\n",
    "labels = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['labels'].flatten()\n",
    "query_idx = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['query_idx'].flatten()\n",
    "with open('PR_data/feature_data.json', 'r') as f:\n",
    "    features = np.array(json.load(f))\n",
    "train_idx -= 1\n",
    "gallery_idx -= 1\n",
    "query_idx -= 1\n",
    "features = np.divide(features,np.amax(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features[train_idx.tolist()]\n",
    "gallery_features = features[gallery_idx.tolist()]\n",
    "query_features = features[query_idx.tolist()]\n",
    "\n",
    "train_label = labels[train_idx.tolist()]\n",
    "gallery_label = labels[gallery_idx.tolist()]\n",
    "query_label = labels[query_idx.tolist()]\n",
    "\n",
    "train_cam = camId[train_idx.tolist()]\n",
    "gallery_cam = camId[gallery_idx.tolist()]\n",
    "query_cam = camId[query_idx.tolist()]\n",
    "\n",
    "labeled_train = np.asarray(list(zip(train_features, train_label, train_cam)))\n",
    "labeled_gallery = np.asarray(list(zip(gallery_features, gallery_label, gallery_cam)))\n",
    "labeled_query = np.asarray(list(zip(query_features, query_label, query_cam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalise training data into input triples and output pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "from more_itertools import locate\n",
    "\n",
    "in_triples_train = np.empty((7368, 3), int)\n",
    "out_pairs_train =  np.empty((7368, 2), int)\n",
    "for i in range(labeled_train.shape[0]) :\n",
    "\n",
    "    \n",
    "    current_id = labeled_train[i][1]\n",
    "    current_cam = labeled_train[i][2]\n",
    "    #ensure there are three unique ID's randomly selected\n",
    "    rand_id1 = rand.choice(train_label)\n",
    "    rand_id2 = rand.choice(train_label)\n",
    "    while not(rand_id1 != current_id) and not(rand_id2 != current_id) and not(rand_id1 != rand_id2) :\n",
    "        rand_id1 = rand.choice(train_label)\n",
    "        rand_id2 = rand.choice(train_label)\n",
    "\n",
    "\n",
    "    triple_set = list(locate(labeled_train, lambda x: \n",
    "                        (x[1] == current_id and x[2] != current_cam)  \n",
    "                        or (x[1] == rand_id1 and x[2] != current_cam)\n",
    "                        or (x[1] == rand_id2 and x[2] != current_cam)\n",
    "                            ))\n",
    "\n",
    "    triple_1 = rand.choice(triple_set)\n",
    "    triple_2 = rand.choice(triple_set)\n",
    "    while triple_1 == triple_2 : \n",
    "        triple_1 = rand.choice(triple_set)\n",
    "        triple_2 = rand.choice(triple_set)\n",
    "\n",
    "    in_triples_train[i] = [triple_1, i, triple_2]\n",
    "\n",
    "    out_pairs_train[i] = [(current_id == labeled_train[triple_1][1]),(current_id == labeled_train[triple_2][1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalise test data into input triple and output pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5328,) (1400,)\n"
     ]
    }
   ],
   "source": [
    "import random as rand\n",
    "from more_itertools import locate\n",
    "print(gallery_idx.shape, query_idx.shape)\n",
    "\n",
    "in_triples_test = np.empty((5328, 3), int)\n",
    "out_pairs_test =  np.empty((5328, 2), int)\n",
    "for i in range(labeled_gallery.shape[0]) :\n",
    "\n",
    "    \n",
    "    current_id = labeled_gallery[i][1]\n",
    "    current_cam = labeled_gallery[i][2]\n",
    "    #ensure there are three unique ID's randomly selected\n",
    "    rand_id1 = rand.choice(query_label)\n",
    "    rand_id2 = rand.choice(query_label)\n",
    "    while not(rand_id1 != current_id) and not(rand_id2 != current_id) and not(rand_id1 != rand_id2) :\n",
    "        rand_id1 = rand.choice(query_label)\n",
    "        rand_id2 = rand.choice(query_label)\n",
    "\n",
    "\n",
    "    triple_set = list(locate(labeled_query, lambda x: \n",
    "                        (x[1] == current_id and x[2] != current_cam)  \n",
    "                        or (x[1] == rand_id1 and x[2] != current_cam)\n",
    "                        or (x[1] == rand_id2 and x[2] != current_cam)\n",
    "                            ))\n",
    "\n",
    "    triple_1 = rand.choice(triple_set)\n",
    "    triple_2 = rand.choice(triple_set)\n",
    "    while triple_1 == triple_2 : \n",
    "        triple_1 = rand.choice(triple_set)\n",
    "        triple_2 = rand.choice(triple_set)\n",
    "\n",
    "    in_triples_test[i] = [triple_1, i, triple_2]\n",
    "\n",
    "    out_pairs_test[i] = [(current_id == labeled_query[triple_1][1]),(current_id == labeled_query[triple_2][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.empty((7368, 3, 2048), float)\n",
    "x_test = np.empty((5328, 3, 2048), float)\n",
    "for i in range(in_triples_train.shape[0]):\n",
    "    x_train[i] = train_features[in_triples_train[i]]\n",
    "for i in range(in_triples_test.shape[0]):\n",
    "    x_test[i][0] = query_features[in_triples_test[i][0]]\n",
    "    x_test[i][1] = gallery_features[in_triples_test[i][1]]\n",
    "    x_test[i][2] = query_features[in_triples_test[i][2]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = out_pairs_train\n",
    "y_test = out_pairs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (3, 2048, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7368 samples, validate on 5328 samples\n",
      "Epoch 1/10\n",
      "7368/7368 [==============================] - 17s 2ms/step - loss: 0.3170 - acc: 0.6796 - val_loss: 0.0583 - val_acc: 0.8277\n",
      "Epoch 2/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1464 - acc: 0.7135 - val_loss: 0.0686 - val_acc: 0.6866\n",
      "Epoch 3/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1406 - acc: 0.7219 - val_loss: 0.0343 - val_acc: 0.8159\n",
      "Epoch 4/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1380 - acc: 0.7224 - val_loss: 0.0279 - val_acc: 0.8348\n",
      "Epoch 5/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1365 - acc: 0.7329 - val_loss: 0.0286 - val_acc: 0.7791\n",
      "Epoch 6/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1355 - acc: 0.7261 - val_loss: 0.0299 - val_acc: 0.8707\n",
      "Epoch 7/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1348 - acc: 0.7212 - val_loss: 0.0244 - val_acc: 0.8223\n",
      "Epoch 8/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1345 - acc: 0.7332 - val_loss: 0.0242 - val_acc: 0.8369\n",
      "Epoch 9/10\n",
      "7368/7368 [==============================] - 11s 2ms/step - loss: 0.1341 - acc: 0.7512 - val_loss: 0.0213 - val_acc: 0.8063\n",
      "Epoch 10/10\n",
      "7368/7368 [==============================] - 12s 2ms/step - loss: 0.1335 - acc: 0.7575 - val_loss: 0.0193 - val_acc: 0.8084\n",
      "Test loss: 0.01934667142282356\n",
      "Test accuracy: 0.8083708708708709\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04604484 0.95395523]]\n"
     ]
    }
   ],
   "source": [
    "x_pred = np.empty((1, 3, 2048), float)\n",
    "x_pred[0][0] = query_features[1]\n",
    "x_pred[0][1] = gallery_features[0]\n",
    "x_pred[0][2] = query_features[0]\n",
    "x_pred = x_pred.reshape(1, 3, 2048, 1)\n",
    "print(model.predict(x_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   3    3    6 ... 1461 1463 1463]\n",
      "[1 2 1 ... 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(query_label)\n",
    "print(query_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
